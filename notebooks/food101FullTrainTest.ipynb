{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6qi-KDLAWG-"
      },
      "source": [
        "# Demostration training and evaluating in all Food101 set\n",
        "In this notebook we will train and test food101 using all the classes. We will split the full food101 data set in the following way:\n",
        "\n",
        "- Train: 70%\n",
        "- Val: 10%\n",
        "- Test: 20%\n",
        "\n",
        "We will use only 70% of the train data to speed the training but we will test our model with 20% of the full dataset.\n",
        "We will train an EfficientB0 model, EfficientB2 model and a Mobilenet_V1 model. In each model we will set the configurations as\n",
        "\n",
        "  - model.pretrained: true\n",
        "  - train.optimizer.lr: 0.001\n",
        "  - train.batch_size: 16\n",
        "  - train.epochs: 15\n",
        "  - train.augmentation: TrivialAugmentWide\n",
        "  - train.unfreeze_layers: 4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz7AYVZVC1F9"
      },
      "source": [
        "# Setup\n",
        "\n",
        "- Mount drive.\n",
        "- Clone repository\n",
        "- Copy data to root\n",
        "- Instal dependencies\n",
        "- Remove data and selected models directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCRvXjjxq2eD",
        "outputId": "0f0ce468-056d-4592-e58c-160b17c0e158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive to save the models during training and evaluating\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zf1_jpNR06iP",
        "outputId": "c4283393-af98-47a1-e61b-d751605874b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'food101-mlops-pipeline'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 126 (delta 14), reused 18 (delta 13), pack-reused 92 (from 2)\u001b[K\n",
            "Receiving objects: 100% (126/126), 23.24 MiB | 15.71 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Jsrodrigue/food101-mlops-pipeline.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVjpjLhR1CUf",
        "outputId": "573b4c68-2fb2-4dc9-cec6-a089072e75e8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending incremental file list\n",
            "./\n",
            ".gitignore\n",
            "\r            216 100%    0.00kB/s    0:00:00  \r            216 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=113/115)\n",
            "LICENSE\n",
            "\r          1,067 100%    1.02MB/s    0:00:00  \r          1,067 100%    1.02MB/s    0:00:00 (xfr#2, to-chk=112/115)\n",
            "README.md\n",
            "\r          6,733 100%    6.42MB/s    0:00:00  \r          6,733 100%    6.42MB/s    0:00:00 (xfr#3, to-chk=111/115)\n",
            "app.py\n",
            "\r          1,666 100%    1.59MB/s    0:00:00  \r          1,666 100%    1.59MB/s    0:00:00 (xfr#4, to-chk=110/115)\n",
            "makefile\n",
            "\r          1,592 100%    1.52MB/s    0:00:00  \r          1,592 100%    1.52MB/s    0:00:00 (xfr#5, to-chk=109/115)\n",
            "requirements.txt\n",
            "\r            377 100%  368.16kB/s    0:00:00  \r            377 100%  368.16kB/s    0:00:00 (xfr#6, to-chk=108/115)\n",
            ".git/\n",
            ".git/HEAD\n",
            "\r             21 100%   10.25kB/s    0:00:00  \r             21 100%   10.25kB/s    0:00:00 (xfr#7, to-chk=101/115)\n",
            ".git/config\n",
            "\r            277 100%  135.25kB/s    0:00:00  \r            277 100%  135.25kB/s    0:00:00 (xfr#8, to-chk=100/115)\n",
            ".git/description\n",
            "\r             73 100%   35.64kB/s    0:00:00  \r             73 100%   35.64kB/s    0:00:00 (xfr#9, to-chk=99/115)\n",
            ".git/index\n",
            "\r          5,347 100%    2.55MB/s    0:00:00  \r          5,347 100%    2.55MB/s    0:00:00 (xfr#10, to-chk=98/115)\n",
            ".git/packed-refs\n",
            "\r            112 100%   54.69kB/s    0:00:00  \r            112 100%   54.69kB/s    0:00:00 (xfr#11, to-chk=97/115)\n",
            ".git/branches/\n",
            ".git/hooks/\n",
            ".git/hooks/applypatch-msg.sample\n",
            "\r            478 100%  233.40kB/s    0:00:00  \r            478 100%  233.40kB/s    0:00:00 (xfr#12, to-chk=90/115)\n",
            ".git/hooks/commit-msg.sample\n",
            "\r            896 100%  437.50kB/s    0:00:00  \r            896 100%  437.50kB/s    0:00:00 (xfr#13, to-chk=89/115)\n",
            ".git/hooks/fsmonitor-watchman.sample\n",
            "\r          4,655 100%    2.22MB/s    0:00:00  \r          4,655 100%    2.22MB/s    0:00:00 (xfr#14, to-chk=88/115)\n",
            ".git/hooks/post-update.sample\n",
            "\r            189 100%   92.29kB/s    0:00:00  \r            189 100%   92.29kB/s    0:00:00 (xfr#15, to-chk=87/115)\n",
            ".git/hooks/pre-applypatch.sample\n",
            "\r            424 100%  207.03kB/s    0:00:00  \r            424 100%  207.03kB/s    0:00:00 (xfr#16, to-chk=86/115)\n",
            ".git/hooks/pre-commit.sample\n",
            "\r          1,643 100%  802.25kB/s    0:00:00  \r          1,643 100%  802.25kB/s    0:00:00 (xfr#17, to-chk=85/115)\n",
            ".git/hooks/pre-merge-commit.sample\n",
            "\r            416 100%  203.12kB/s    0:00:00  \r            416 100%  203.12kB/s    0:00:00 (xfr#18, to-chk=84/115)\n",
            ".git/hooks/pre-push.sample\n",
            "\r          1,374 100%  670.90kB/s    0:00:00  \r          1,374 100%  670.90kB/s    0:00:00 (xfr#19, to-chk=83/115)\n",
            ".git/hooks/pre-rebase.sample\n",
            "\r          4,898 100%    2.34MB/s    0:00:00  \r          4,898 100%    2.34MB/s    0:00:00 (xfr#20, to-chk=82/115)\n",
            ".git/hooks/pre-receive.sample\n",
            "\r            544 100%  265.62kB/s    0:00:00  \r            544 100%  265.62kB/s    0:00:00 (xfr#21, to-chk=81/115)\n",
            ".git/hooks/prepare-commit-msg.sample\n",
            "\r          1,492 100%  728.52kB/s    0:00:00  \r          1,492 100%  728.52kB/s    0:00:00 (xfr#22, to-chk=80/115)\n",
            ".git/hooks/push-to-checkout.sample\n",
            "\r          2,783 100%    1.33MB/s    0:00:00  \r          2,783 100%    1.33MB/s    0:00:00 (xfr#23, to-chk=79/115)\n",
            ".git/hooks/update.sample\n",
            "\r          3,650 100%    1.74MB/s    0:00:00  \r          3,650 100%    1.74MB/s    0:00:00 (xfr#24, to-chk=78/115)\n",
            ".git/info/\n",
            ".git/info/exclude\n",
            "\r            240 100%  117.19kB/s    0:00:00  \r            240 100%  117.19kB/s    0:00:00 (xfr#25, to-chk=77/115)\n",
            ".git/logs/\n",
            ".git/logs/HEAD\n",
            "\r            200 100%   97.66kB/s    0:00:00  \r            200 100%   97.66kB/s    0:00:00 (xfr#26, to-chk=76/115)\n",
            ".git/logs/refs/\n",
            ".git/logs/refs/heads/\n",
            ".git/logs/refs/heads/main\n",
            "\r            200 100%   97.66kB/s    0:00:00  \r            200 100%   97.66kB/s    0:00:00 (xfr#27, to-chk=72/115)\n",
            ".git/logs/refs/remotes/\n",
            ".git/logs/refs/remotes/origin/\n",
            ".git/logs/refs/remotes/origin/HEAD\n",
            "\r            200 100%   97.66kB/s    0:00:00  \r            200 100%   97.66kB/s    0:00:00 (xfr#28, to-chk=70/115)\n",
            ".git/objects/\n",
            ".git/objects/info/\n",
            ".git/objects/pack/\n",
            ".git/objects/pack/pack-d02450b681f2f27a58e62b42fce449c4a8609faa.idx\n",
            "\r          4,600 100%    2.19MB/s    0:00:00  \r          4,600 100%    2.19MB/s    0:00:00 (xfr#29, to-chk=67/115)\n",
            ".git/objects/pack/pack-d02450b681f2f27a58e62b42fce449c4a8609faa.pack\n",
            "\r         32,768   0%   10.42MB/s    0:00:02  \r     24,373,729 100%  628.23MB/s    0:00:00 (xfr#30, to-chk=66/115)\n",
            ".git/refs/\n",
            ".git/refs/heads/\n",
            ".git/refs/heads/main\n",
            "\r             41 100%    1.08kB/s    0:00:00  \r             41 100%    1.08kB/s    0:00:00 (xfr#31, to-chk=62/115)\n",
            ".git/refs/remotes/\n",
            ".git/refs/remotes/origin/\n",
            ".git/refs/remotes/origin/HEAD\n",
            "\r             30 100%    0.79kB/s    0:00:00  \r             30 100%    0.79kB/s    0:00:00 (xfr#32, to-chk=60/115)\n",
            ".git/refs/tags/\n",
            "conf/\n",
            "conf/config.yaml\n",
            "\r            258 100%    6.81kB/s    0:00:00  \r            258 100%    6.81kB/s    0:00:00 (xfr#33, to-chk=59/115)\n",
            "conf/dataset/\n",
            "conf/dataset/dataset.yaml\n",
            "\r            521 100%   13.75kB/s    0:00:00  \r            521 100%   13.75kB/s    0:00:00 (xfr#34, to-chk=50/115)\n",
            "conf/experiments/\n",
            "conf/experiments/experiments.yaml\n",
            "\r          1,026 100%   27.08kB/s    0:00:00  \r          1,026 100%   27.08kB/s    0:00:00 (xfr#35, to-chk=49/115)\n",
            "conf/model/\n",
            "conf/model/efficientnet.yaml\n",
            "\r             47 100%    1.24kB/s    0:00:00  \r             47 100%    1.24kB/s    0:00:00 (xfr#36, to-chk=48/115)\n",
            "conf/model/mobilenet.yaml\n",
            "\r             44 100%    1.16kB/s    0:00:00  \r             44 100%    1.16kB/s    0:00:00 (xfr#37, to-chk=47/115)\n",
            "conf/outputs/\n",
            "conf/outputs/outputs.yaml\n",
            "\r            172 100%    4.54kB/s    0:00:00  \r            172 100%    4.54kB/s    0:00:00 (xfr#38, to-chk=46/115)\n",
            "conf/retrain/\n",
            "conf/retrain/retrain.yaml\n",
            "\r            327 100%    8.63kB/s    0:00:00  \r            327 100%    8.63kB/s    0:00:00 (xfr#39, to-chk=45/115)\n",
            "conf/select_model/\n",
            "conf/select_model/select_model.yaml\n",
            "\r            326 100%    8.60kB/s    0:00:00  \r            326 100%    8.60kB/s    0:00:00 (xfr#40, to-chk=44/115)\n",
            "conf/test/\n",
            "conf/test/test.yaml\n",
            "\r            203 100%    5.36kB/s    0:00:00  \r            203 100%    5.36kB/s    0:00:00 (xfr#41, to-chk=43/115)\n",
            "conf/train/\n",
            "conf/train/train.yaml\n",
            "\r            499 100%   13.17kB/s    0:00:00  \r            499 100%   13.17kB/s    0:00:00 (xfr#42, to-chk=42/115)\n",
            "notebooks/\n",
            "notebooks/InitialExploration.ipynb\n",
            "\r         32,768   0%  864.86kB/s    0:00:13  \r     11,730,305 100%  211.07MB/s    0:00:00 (xfr#43, to-chk=41/115)\n",
            "scripts/\n",
            "scripts/__init__.py\n",
            "\r              0 100%    0.00kB/s    0:00:00 (xfr#44, to-chk=40/115)\n",
            "scripts/orchestrator.py\n",
            "\r            529 100%    9.75kB/s    0:00:00  \r            529 100%    9.75kB/s    0:00:00 (xfr#45, to-chk=39/115)\n",
            "scripts/retrain.py\n",
            "\r          4,297 100%   79.18kB/s    0:00:00  \r          4,297 100%   79.18kB/s    0:00:00 (xfr#46, to-chk=38/115)\n",
            "scripts/run_experiments.py\n",
            "\r          1,106 100%   20.38kB/s    0:00:00  \r          1,106 100%   20.38kB/s    0:00:00 (xfr#47, to-chk=37/115)\n",
            "scripts/save_data.py\n",
            "\r            253 100%    4.66kB/s    0:00:00  \r            253 100%    4.66kB/s    0:00:00 (xfr#48, to-chk=36/115)\n",
            "scripts/select_models.py\n",
            "\r          1,014 100%   18.68kB/s    0:00:00  \r          1,014 100%   18.68kB/s    0:00:00 (xfr#49, to-chk=35/115)\n",
            "scripts/test.py\n",
            "\r          3,287 100%   60.57kB/s    0:00:00  \r          3,287 100%   60.57kB/s    0:00:00 (xfr#50, to-chk=34/115)\n",
            "scripts/train.py\n",
            "\r          3,246 100%   59.81kB/s    0:00:00  \r          3,246 100%   59.81kB/s    0:00:00 (xfr#51, to-chk=33/115)\n",
            "selected_models/\n",
            "selected_models/efficientnet_b0_3956c/\n",
            "selected_models/efficientnet_b0_3956c/artifacts/\n",
            "selected_models/efficientnet_b0_3956c/artifacts/best_model_info/\n",
            "selected_models/efficientnet_b0_3956c/artifacts/best_model_info/best_model_info.json\n",
            "\r          3,213 100%   59.20kB/s    0:00:00  \r          3,213 100%   59.20kB/s    0:00:00 (xfr#52, to-chk=26/115)\n",
            "selected_models/efficientnet_b0_3956c/artifacts/metrics/\n",
            "selected_models/efficientnet_b0_3956c/artifacts/metrics/training_results.json\n",
            "\r          4,707 100%   86.73kB/s    0:00:00  \r          4,707 100%   86.73kB/s    0:00:00 (xfr#53, to-chk=25/115)\n",
            "selected_models/efficientnet_b0_3956c/artifacts/model/\n",
            "selected_models/efficientnet_b0_3956c/artifacts/model/model_state_dict.pth\n",
            "\r         32,768   0%  592.59kB/s    0:00:28  \r     16,849,421 100%  208.69MB/s    0:00:00 (xfr#54, to-chk=24/115)\n",
            "selected_models/efficientnet_b0_3956c/artifacts/plots/\n",
            "selected_models/efficientnet_b0_3956c/artifacts/plots/loss_curve.png\n",
            "\r         32,644 100%  414.01kB/s    0:00:00  \r         32,644 100%  414.01kB/s    0:00:00 (xfr#55, to-chk=23/115)\n",
            "src/\n",
            "src/__init__.py\n",
            "\r              0 100%    0.00kB/s    0:00:00 (xfr#56, to-chk=22/115)\n",
            "src/data_engine.py\n",
            "\r          9,095 100%  115.35kB/s    0:00:00  \r          9,095 100%  115.35kB/s    0:00:00 (xfr#57, to-chk=21/115)\n",
            "src/data_setup.py\n",
            "\r          1,949 100%   24.72kB/s    0:00:00  \r          1,949 100%   24.72kB/s    0:00:00 (xfr#58, to-chk=20/115)\n",
            "src/predictions.py\n",
            "\r          1,738 100%   22.04kB/s    0:00:00  \r          1,738 100%   22.04kB/s    0:00:00 (xfr#59, to-chk=19/115)\n",
            "src/st_sections.py\n",
            "\r         13,514 100%  171.39kB/s    0:00:00  \r         13,514 100%  171.39kB/s    0:00:00 (xfr#60, to-chk=18/115)\n",
            "src/test_engine.py\n",
            "\r          3,313 100%   42.02kB/s    0:00:00  \r          3,313 100%   42.02kB/s    0:00:00 (xfr#61, to-chk=17/115)\n",
            "src/train_engine.py\n",
            "\r          8,599 100%  109.06kB/s    0:00:00  \r          8,599 100%  109.06kB/s    0:00:00 (xfr#62, to-chk=16/115)\n",
            "src/models/\n",
            "src/models/__init__.py\n",
            "\r            172 100%    2.18kB/s    0:00:00  \r            172 100%    2.18kB/s    0:00:00 (xfr#63, to-chk=13/115)\n",
            "src/models/efficientnet_models.py\n",
            "\r          2,937 100%   37.25kB/s    0:00:00  \r          2,937 100%   37.25kB/s    0:00:00 (xfr#64, to-chk=12/115)\n",
            "src/models/mobilenet_models.py\n",
            "\r          2,453 100%   31.11kB/s    0:00:00  \r          2,453 100%   31.11kB/s    0:00:00 (xfr#65, to-chk=11/115)\n",
            "src/utils/\n",
            "src/utils/__init__.py\n",
            "\r              0 100%    0.00kB/s    0:00:00 (xfr#66, to-chk=10/115)\n",
            "src/utils/data_setup_utils.py\n",
            "\r          1,017 100%   12.90kB/s    0:00:00  \r          1,017 100%   12.90kB/s    0:00:00 (xfr#67, to-chk=9/115)\n",
            "src/utils/eval_utils.py\n",
            "\r          1,993 100%   25.28kB/s    0:00:00  \r          1,993 100%   25.28kB/s    0:00:00 (xfr#68, to-chk=8/115)\n",
            "src/utils/metrics.py\n",
            "\r            808 100%   10.25kB/s    0:00:00  \r            808 100%   10.25kB/s    0:00:00 (xfr#69, to-chk=7/115)\n",
            "src/utils/mlflow_utils.py\n",
            "\r          6,536 100%   82.89kB/s    0:00:00  \r          6,536 100%   82.89kB/s    0:00:00 (xfr#70, to-chk=6/115)\n",
            "src/utils/model_utils.py\n",
            "\r          3,051 100%   38.69kB/s    0:00:00  \r          3,051 100%   38.69kB/s    0:00:00 (xfr#71, to-chk=5/115)\n",
            "src/utils/plot_utils.py\n",
            "\r            792 100%   10.04kB/s    0:00:00  \r            792 100%   10.04kB/s    0:00:00 (xfr#72, to-chk=4/115)\n",
            "src/utils/render_utils.py\n",
            "\r          3,648 100%   46.27kB/s    0:00:00  \r          3,648 100%   46.27kB/s    0:00:00 (xfr#73, to-chk=3/115)\n",
            "src/utils/runs_utils.py\n",
            "\r          6,076 100%   77.06kB/s    0:00:00  \r          6,076 100%   77.06kB/s    0:00:00 (xfr#74, to-chk=2/115)\n",
            "src/utils/seed_utils.py\n",
            "\r            219 100%    2.78kB/s    0:00:00  \r            219 100%    2.78kB/s    0:00:00 (xfr#75, to-chk=1/115)\n",
            "src/utils/st_utils.py\n",
            "\r          2,177 100%   27.61kB/s    0:00:00  \r          2,177 100%   27.61kB/s    0:00:00 (xfr#76, to-chk=0/115)\n",
            "\n",
            "sent 53,147,225 bytes  received 1,647 bytes  106,297,744.00 bytes/sec\n",
            "total size is 53,127,695  speedup is 1.00\n"
          ]
        }
      ],
      "source": [
        "# Move repo to content\n",
        "!rsync -av --progress /content/food101-mlops-pipeline/ /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y6k8w97Y_nI5",
        "outputId": "2732588d-d3da-4861-e20a-b813a38a0483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.23.0+cu126)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: numpy==2.0.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Collecting mlflow==3.4.0 (from -r requirements.txt (line 10))\n",
            "  Downloading mlflow-3.4.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting hydra-core==1.3.2 (from -r requirements.txt (line 11))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (6.0.3)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.1.1)\n",
            "Requirement already satisfied: matplotlib==3.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (0.13.2)\n",
            "Collecting streamlit>=1.24.1 (from -r requirements.txt (line 20))\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (11.3.0)\n",
            "Requirement already satisfied: altair>=5.0.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (5.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 6)) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.6.1->-r requirements.txt (line 6)) (3.6.0)\n",
            "Collecting mlflow-skinny==3.4.0 (from mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.4.0 (from mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading mlflow_tracing-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.4.0->-r requirements.txt (line 10)) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.4.0->-r requirements.txt (line 10)) (1.16.5)\n",
            "Requirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.4.0->-r requirements.txt (line 10)) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fastmcp<3,>=2.0.0 (from mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading fastmcp-2.12.4-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting graphene<4 (from mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.4.0->-r requirements.txt (line 10)) (18.1.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow==3.4.0->-r requirements.txt (line 10)) (2.0.43)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2->-r requirements.txt (line 11)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2->-r requirements.txt (line 11)) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2->-r requirements.txt (line 11)) (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.10.0->-r requirements.txt (line 16)) (3.2.5)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (8.3.0)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading databricks_sdk-0.67.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.118.2)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (1.37.0)\n",
            "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.11.10)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.37.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.24.1->-r requirements.txt (line 20)) (1.9.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.24.1->-r requirements.txt (line 20)) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.24.1->-r requirements.txt (line 20)) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.24.1->-r requirements.txt (line 20)) (6.0.0)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit>=1.24.1->-r requirements.txt (line 20))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.24.1->-r requirements.txt (line 20)) (6.4.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair>=5.0.1->-r requirements.txt (line 22)) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair>=5.0.1->-r requirements.txt (line 22)) (2.7.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow==3.4.0->-r requirements.txt (line 10)) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46,>=43.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.5.0)\n",
            "Requirement already satisfied: authlib>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (1.6.5)\n",
            "Collecting cyclopts>=3.0.0 (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting exceptiongroup>=1.2.2 (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.28.1)\n",
            "Requirement already satisfied: mcp<2.0.0,>=1.12.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (1.16.0)\n",
            "Collecting openapi-core>=0.19.5 (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting openapi-pydantic>=0.5.1 (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (1.11.0)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (13.9.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.4.0->-r requirements.txt (line 10)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.4.0->-r requirements.txt (line 10)) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow==3.4.0->-r requirements.txt (line 10)) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (4.0.12)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair>=5.0.1->-r requirements.txt (line 22)) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair>=5.0.1->-r requirements.txt (line 22)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair>=5.0.1->-r requirements.txt (line 22)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair>=5.0.1->-r requirements.txt (line 22)) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.23)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.17.0)\n",
            "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.48.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (3.23.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.4.2)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (3.0.2)\n",
            "Collecting isodate (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (10.8.0)\n",
            "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting parse (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.4.2)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (2.19.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (1.3.1)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (4.9.1)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.1.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.1.4)\n",
            "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10))\n",
            "  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.21.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow==3.4.0->-r requirements.txt (line 10)) (0.6.1)\n",
            "Downloading mlflow-3.4.0-py3-none-any.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.4.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastmcp-2.12.4-py3-none-any.whl (329 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m139.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.2/86.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.67.0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.4/718.4 kB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Downloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\n",
            "Downloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\n",
            "Downloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: parse, werkzeug, pathable, opentelemetry-proto, lazy-object-proxy, isodate, gunicorn, graphql-core, exceptiongroup, dnspython, pydeck, jsonschema-path, hydra-core, graphql-relay, email-validator, docker, rich-rst, openapi-pydantic, graphene, databricks-sdk, openapi-schema-validator, cyclopts, streamlit, openapi-spec-validator, mlflow-tracing, mlflow-skinny, openapi-core, fastmcp, mlflow\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "Successfully installed cyclopts-3.24.0 databricks-sdk-0.67.0 dnspython-2.8.0 docker-7.1.0 email-validator-2.3.0 exceptiongroup-1.3.0 fastmcp-2.12.4 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 hydra-core-1.3.2 isodate-0.7.2 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 mlflow-3.4.0 mlflow-skinny-3.4.0 mlflow-tracing-3.4.0 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 opentelemetry-proto-1.37.0 parse-1.20.2 pathable-0.4.4 pydeck-0.9.1 rich-rst-1.3.1 streamlit-1.50.0 werkzeug-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading data\n",
        "We can download the data from google drive or using our script save_data.py"
      ],
      "metadata": {
        "id": "wKuEgfT6p_st"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Download from drive"
      ],
      "metadata": {
        "id": "AJpTiVGwqISm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be sure that we are using always the same dataset, we prefere to download the data from google drive."
      ],
      "metadata": {
        "id": "Lzn16go61Juf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gdown to download from Google Drive\n",
        "!pip install -q gdown\n",
        "\n",
        "# Downliad from drive\n",
        "!gdown \"https://drive.google.com/uc?id=1FxQ1B1GDdpwtzLGBKSW_XALEq70RVMM9\"\n",
        "\n",
        "# Unzip data:\n",
        "!unzip -q /content/fullfood101_dataset.zip -d /content/\n",
        "\n",
        "# Verify content in data\n",
        "!find /content/data -type f | wc -l\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv9jVc8vg8NP",
        "outputId": "7f5eb245-cedf-4c81-d8e4-47190f577611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1FxQ1B1GDdpwtzLGBKSW_XALEq70RVMM9\n",
            "From (redirected): https://drive.google.com/uc?id=1FxQ1B1GDdpwtzLGBKSW_XALEq70RVMM9&confirm=t&uuid=74622818-58f6-49cc-a77d-55dde1447c23\n",
            "To: /content/fullfood101_dataset.zip\n",
            "100% 5.00G/5.00G [01:09<00:00, 71.5MB/s]\n",
            "101001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2: Using our script"
      ],
      "metadata": {
        "id": "MRWrwVPUqXFr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVn5Q2sWGNVm"
      },
      "source": [
        "For this demostration it is important to configure the `dataset.yaml` file to download all the food101 dataset by setting:\n",
        " - `creation.select_mode: first`\n",
        " - `samples_per_class: 1000`\n",
        " - `num_classes: 101`\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "It is also possible to save the data by replacing the cell `make prepare` with\n",
        "\n",
        "`!python -m scripts.save_data dataset.creation.select_mode=first dataset.creation.samples_per_class=1000 dataset.creation.num_classes=101`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ILppbs8K2r9a",
        "outputId": "93aee933-27eb-4ce1-fc86-ff8b2ccf4469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Downloading Food101 dataset...\n",
            "100% 5.00G/5.00G [08:40<00:00, 9.60MB/s]\n",
            "[INFO] Download completed.\n",
            "[INFO] Using classes: ['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
            "[INFO] Split sizes per class → Train=700, Val=100, Test=200\n",
            "[INFO] Processing classes: 100% 101/101 [01:35<00:00,  1.06it/s]\n",
            "[INFO] Subset created successfully at /content/data/dataset\n",
            "[INFO] Class mapping saved at: /content/data/class_map.json\n",
            "[INFO] Alphabetical class order: ['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
            "[INFO] Removing unzipped folder: /content/data/dataset/food-101\n"
          ]
        }
      ],
      "source": [
        "#!python -m scripts.save_data dataset.creation.select_mode=first dataset.creation.samples_per_class=1000 dataset.creation.num_classes=101\n",
        "#!make prepare  # be sure to set the configurations as above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZUEJeJevbR3"
      },
      "outputs": [],
      "source": [
        "# -------------- Run If Needed -------------------------\n",
        "\n",
        "# Remove selected models and data if exists to create our own\n",
        "#!rm -rf selected_models\n",
        "#!rm -rf data\n",
        "#!rm -rf food101-mlops-pipeline/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOwaVwQ6ASWa"
      },
      "source": [
        "# Training\n",
        "For reasons of computational resourses and to avoid session disconection before finish our experiments, we will run each experiment one at the time and use the train scrpit instead of the experimation script. We will save the models in each step of the process in google drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRARnDzvH8M9"
      },
      "source": [
        "## EfficientB0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.train \\\n",
        "    model=efficientnet model.version=b0 \\\n",
        "    model.pretrained=true \\\n",
        "    train.optimizer.lr=0.001 \\\n",
        "    train.batch_size=16 \\\n",
        "    train.epochs=15 \\\n",
        "    train.augmentation=TrivialAugmentWide \\\n",
        "    train.unfreeze_layers=4 \\\n",
        "    train.subset_percentage=0.7 \\\n",
        "    train.scheduler.type=ReduceLROnPlateau \\\n",
        "    outputs.local.mlflow.path=\"/content/drive/MyDrive/mlruns\" \\\n",
        "    outputs.local.mlflow.artifact_dir=\"/content/drive/MyDrive/artifacts\""
      ],
      "metadata": {
        "id": "nvRFe8oo_FPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457eaca3-a2b9-4818-9609-9609913851d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "\r  0% 0.00/20.5M [00:00<?, ?B/s]\r 72% 14.8M/20.5M [00:00<00:00, 155MB/s]\r100% 20.5M/20.5M [00:00<00:00, 174MB/s]\n",
            "[INFO] Starting training...\n",
            "Training:   0% 0/15 [00:00<?, ?it/s][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 1: Train: accuracy 0.3524, precision_macro 0.3374, recall_macro 0.3526, f1_macro 0.3409, loss 2.8078\n",
            "        Val: accuracy 0.5173, precision_macro 0.5294, recall_macro 0.5173, f1_macro 0.5075, loss 1.9807\n",
            "\n",
            "[INFO] New best model saved at epoch 0 with val_loss=1.9807\n",
            "Training:   7% 1/15 [07:56<1:51:16, 476.92s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 2: Train: accuracy 0.4334, precision_macro 0.4215, recall_macro 0.4337, f1_macro 0.4255, loss 2.3500\n",
            "        Val: accuracy 0.5383, precision_macro 0.5441, recall_macro 0.5383, f1_macro 0.5281, loss 1.8642\n",
            "\n",
            "[INFO] New best model saved at epoch 1 with val_loss=1.8642\n",
            "Training:  13% 2/15 [15:52<1:43:06, 475.90s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 3: Train: accuracy 0.5103, precision_macro 0.5025, recall_macro 0.5104, f1_macro 0.5051, loss 1.9542\n",
            "        Val: accuracy 0.6595, precision_macro 0.6741, recall_macro 0.6595, f1_macro 0.6555, loss 1.3165\n",
            "\n",
            "[INFO] New best model saved at epoch 2 with val_loss=1.3165\n",
            "Training:  20% 3/15 [24:09<1:37:10, 485.87s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 4: Train: accuracy 0.6001, precision_macro 0.5953, recall_macro 0.6002, f1_macro 0.5970, loss 1.5510\n",
            "        Val: accuracy 0.7060, precision_macro 0.7159, recall_macro 0.7060, f1_macro 0.7028, loss 1.1497\n",
            "\n",
            "[INFO] New best model saved at epoch 3 with val_loss=1.1497\n",
            "Training:  27% 4/15 [32:36<1:30:36, 494.25s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 5: Train: accuracy 0.6398, precision_macro 0.6366, recall_macro 0.6398, f1_macro 0.6376, loss 1.3796\n",
            "        Val: accuracy 0.7140, precision_macro 0.7214, recall_macro 0.7140, f1_macro 0.7107, loss 1.1172\n",
            "\n",
            "[INFO] New best model saved at epoch 4 with val_loss=1.1172\n",
            "Training:  33% 5/15 [41:04<1:23:09, 498.99s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 6: Train: accuracy 0.6694, precision_macro 0.6663, recall_macro 0.6695, f1_macro 0.6673, loss 1.2616\n",
            "        Val: accuracy 0.7342, precision_macro 0.7444, recall_macro 0.7342, f1_macro 0.7327, loss 1.0318\n",
            "\n",
            "[INFO] New best model saved at epoch 5 with val_loss=1.0318\n",
            "Training:  40% 6/15 [49:29<1:15:11, 501.23s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 7: Train: accuracy 0.6899, precision_macro 0.6874, recall_macro 0.6899, f1_macro 0.6882, loss 1.1607\n",
            "        Val: accuracy 0.7306, precision_macro 0.7407, recall_macro 0.7306, f1_macro 0.7295, loss 1.0815\n",
            "\n",
            "[EarlyStopping] No improvement for 1 epoch(s)\n",
            "Training:  47% 7/15 [57:49<1:06:45, 500.66s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 8: Train: accuracy 0.7130, precision_macro 0.7111, recall_macro 0.7130, f1_macro 0.7116, loss 1.0772\n",
            "        Val: accuracy 0.7488, precision_macro 0.7565, recall_macro 0.7488, f1_macro 0.7483, loss 1.0127\n",
            "\n",
            "[INFO] New best model saved at epoch 7 with val_loss=1.0127\n",
            "Training:  53% 8/15 [1:06:17<58:42, 503.14s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 9: Train: accuracy 0.7251, precision_macro 0.7233, recall_macro 0.7251, f1_macro 0.7238, loss 1.0201\n",
            "        Val: accuracy 0.7599, precision_macro 0.7672, recall_macro 0.7599, f1_macro 0.7586, loss 0.9855\n",
            "\n",
            "[INFO] New best model saved at epoch 8 with val_loss=0.9855\n",
            "Training:  60% 9/15 [1:14:44<50:26, 504.39s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 10: Train: accuracy 0.7434, precision_macro 0.7422, recall_macro 0.7435, f1_macro 0.7425, loss 0.9506\n",
            "        Val: accuracy 0.7597, precision_macro 0.7644, recall_macro 0.7597, f1_macro 0.7580, loss 0.9839\n",
            "\n",
            "[INFO] New best model saved at epoch 9 with val_loss=0.9839\n",
            "Training:  67% 10/15 [1:23:10<42:03, 504.70s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 11: Train: accuracy 0.7578, precision_macro 0.7565, recall_macro 0.7579, f1_macro 0.7568, loss 0.8937\n",
            "        Val: accuracy 0.7637, precision_macro 0.7668, recall_macro 0.7637, f1_macro 0.7618, loss 0.9833\n",
            "\n",
            "[INFO] New best model saved at epoch 10 with val_loss=0.9833\n",
            "Training:  73% 11/15 [1:31:38<33:43, 505.82s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 12: Train: accuracy 0.7686, precision_macro 0.7673, recall_macro 0.7686, f1_macro 0.7676, loss 0.8472\n",
            "        Val: accuracy 0.7583, precision_macro 0.7651, recall_macro 0.7583, f1_macro 0.7563, loss 1.0144\n",
            "\n",
            "[EarlyStopping] No improvement for 1 epoch(s)\n",
            "Training:  80% 12/15 [1:39:50<25:04, 501.56s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 13: Train: accuracy 0.7790, precision_macro 0.7782, recall_macro 0.7790, f1_macro 0.7783, loss 0.8026\n",
            "        Val: accuracy 0.7625, precision_macro 0.7664, recall_macro 0.7625, f1_macro 0.7611, loss 1.0004\n",
            "\n",
            "[EarlyStopping] No improvement for 2 epoch(s)\n",
            "Training:  87% 13/15 [1:48:04<16:38, 499.19s/it][INFO] Starting train step...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m scripts.retrain \\\n",
        "outputs.local.mlflow.path=/content/drive/MyDrive/mlruns \\\n",
        "outputs.local.mlflow.artifact_dir=/content/drive/MyDrive/artifacts \\\n",
        "retrain.run_path=/content/drive/MyDrive/mlruns/186912651824771251/70dc7de78d194823a1b5a06eaf820444 \\\n",
        "retrain.epochs_extra=5 \\\n",
        "train.optimizer.lr=0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv_r5NPTQGQL",
        "outputId": "f7abd8f2-6499-485f-b1e2-b27ff88871dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Continuing training from run /content/drive/MyDrive/mlruns/186912651824771251/70dc7de78d194823a1b5a06eaf820444\n",
            "[WARN] No training_results.json found, reconstructing from metrics folder...\n",
            "Training:   0% 0/5 [00:00<?, ?it/s][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 14: Train: accuracy 0.7727, precision_macro 0.7719, recall_macro 0.7727, f1_macro 0.7720, loss 0.8341\n",
            "        Val: accuracy 0.7582, precision_macro 0.7640, recall_macro 0.7582, f1_macro 0.7563, loss 1.0241\n",
            "\n",
            "Training:  20% 1/5 [08:37<34:30, 517.55s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 15: Train: accuracy 0.7858, precision_macro 0.7849, recall_macro 0.7858, f1_macro 0.7851, loss 0.7839\n",
            "        Val: accuracy 0.7621, precision_macro 0.7640, recall_macro 0.7621, f1_macro 0.7595, loss 0.9885\n",
            "\n",
            "[INFO] New best model saved at epoch 14 with val_loss=0.9885\n",
            "Training:  40% 2/5 [17:21<26:04, 521.44s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 16: Train: accuracy 0.7928, precision_macro 0.7920, recall_macro 0.7928, f1_macro 0.7921, loss 0.7515\n",
            "        Val: accuracy 0.7623, precision_macro 0.7664, recall_macro 0.7623, f1_macro 0.7610, loss 1.0187\n",
            "\n",
            "[EarlyStopping] No improvement for 1 epoch(s)\n",
            "Training:  60% 3/5 [26:13<17:32, 526.33s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 17: Train: accuracy 0.8046, precision_macro 0.8042, recall_macro 0.8047, f1_macro 0.8042, loss 0.7064\n",
            "        Val: accuracy 0.7695, precision_macro 0.7745, recall_macro 0.7695, f1_macro 0.7688, loss 1.0044\n",
            "\n",
            "[EarlyStopping] No improvement for 2 epoch(s)\n",
            "Training:  80% 4/5 [34:59<08:46, 526.03s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 18: Train: accuracy 0.8179, precision_macro 0.8172, recall_macro 0.8179, f1_macro 0.8174, loss 0.6604\n",
            "        Val: accuracy 0.7704, precision_macro 0.7750, recall_macro 0.7704, f1_macro 0.7693, loss 1.0398\n",
            "\n",
            "[EarlyStopping] No improvement for 3 epoch(s)\n",
            "Training: 100% 5/5 [43:47<00:00, 525.43s/it]\n",
            "[INFO] Plot logged in MLflow run 40a01a2d1e004c6085b328102f01c32b\n",
            "[INFO] Plot URI: file:///content/drive/MyDrive/mlruns/186912651824771251/40a01a2d1e004c6085b328102f01c32b/artifacts/plots/loss_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-SMX-rgIB0C"
      },
      "source": [
        "## EfficientB2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9ThNcL2siQb"
      },
      "source": [
        "From here I change the strategy and decided to make two epochs frozen (warming training) and then unfreeze the layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3C_ayFBIE48",
        "outputId": "d9518d17-ab84-4c52-c508-3b2768c36185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Starting training...\n",
            "Training:   0% 0/15 [00:00<?, ?it/s][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 1: Train: accuracy 0.3791, precision_macro 0.3647, recall_macro 0.3793, f1_macro 0.3687, loss 2.7123\n",
            "        Val: accuracy 0.5472, precision_macro 0.5520, recall_macro 0.5472, f1_macro 0.5352, loss 1.8664\n",
            "\n",
            "[INFO] New best model saved at epoch 0 with val_loss=1.8664\n",
            "Training:   7% 1/15 [09:38<2:15:01, 578.68s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 2: Train: accuracy 0.4654, precision_macro 0.4548, recall_macro 0.4657, f1_macro 0.4586, loss 2.2057\n",
            "        Val: accuracy 0.5726, precision_macro 0.5702, recall_macro 0.5726, f1_macro 0.5588, loss 1.7110\n",
            "\n",
            "[INFO] New best model saved at epoch 1 with val_loss=1.7110\n",
            "Training:  13% 2/15 [19:28<2:06:45, 585.02s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 3: Train: accuracy 0.5498, precision_macro 0.5429, recall_macro 0.5499, f1_macro 0.5454, loss 1.7720\n",
            "        Val: accuracy 0.7002, precision_macro 0.7165, recall_macro 0.7002, f1_macro 0.6969, loss 1.1631\n",
            "\n",
            "[INFO] New best model saved at epoch 2 with val_loss=1.1631\n",
            "Training:  20% 3/15 [30:02<2:01:31, 607.62s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 4: Train: accuracy 0.6430, precision_macro 0.6392, recall_macro 0.6431, f1_macro 0.6405, loss 1.3686\n",
            "        Val: accuracy 0.7366, precision_macro 0.7478, recall_macro 0.7366, f1_macro 0.7350, loss 1.0197\n",
            "\n",
            "[INFO] New best model saved at epoch 3 with val_loss=1.0197\n",
            "Training:  27% 4/15 [40:36<1:53:18, 618.07s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 5: Train: accuracy 0.6824, precision_macro 0.6797, recall_macro 0.6824, f1_macro 0.6806, loss 1.1988\n",
            "        Val: accuracy 0.7542, precision_macro 0.7594, recall_macro 0.7542, f1_macro 0.7508, loss 0.9699\n",
            "\n",
            "[INFO] New best model saved at epoch 4 with val_loss=0.9699\n",
            "Training:  33% 5/15 [51:16<1:44:17, 625.77s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 6: Train: accuracy 0.7118, precision_macro 0.7098, recall_macro 0.7118, f1_macro 0.7104, loss 1.0765\n",
            "        Val: accuracy 0.7641, precision_macro 0.7744, recall_macro 0.7641, f1_macro 0.7630, loss 0.9199\n",
            "\n",
            "[INFO] New best model saved at epoch 5 with val_loss=0.9199\n",
            "Training:  40% 6/15 [1:01:52<1:34:23, 629.24s/it][INFO] Starting train step...\n"
          ]
        }
      ],
      "source": [
        "!python -m scripts.train \\\n",
        "    model=efficientnet model.version=b2 \\\n",
        "    model.pretrained=true \\\n",
        "    train.optimizer.lr=0.001 \\\n",
        "    train.batch_size=16 \\\n",
        "    train.epochs=15 \\\n",
        "    train.augmentation=TrivialAugmentWide \\\n",
        "    train.unfreeze_layers=4 \\\n",
        "    train.subset_percentage=0.7 \\\n",
        "    train.scheduler.type=ReduceLROnPlateau \\\n",
        "    outputs.local.mlflow.path=\"/content/drive/MyDrive/mlruns\" \\\n",
        "    outputs.local.mlflow.artifact_dir=\"/content/drive/MyDrive/artifacts\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSjk8TO6Lcf-",
        "outputId": "4f96de40-a4fa-45cf-fd07-5019ec82f713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100% 35.2M/35.2M [00:00<00:00, 168MB/s]\n",
            "[INFO] Continuing training from run /content/drive/MyDrive/mlruns/186912651824771251/5b50bf196aa441f794d71e132c2dff47\n",
            "[WARN] No training_results.json found, reconstructing from metrics folder...\n",
            "Training:   0% 0/7 [00:00<?, ?it/s][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 7: Train: accuracy 0.7396, precision_macro 0.7383, recall_macro 0.7396, f1_macro 0.7387, loss 0.9681\n",
            "        Val: accuracy 0.7689, precision_macro 0.7758, recall_macro 0.7689, f1_macro 0.7678, loss 0.9188\n",
            "\n",
            "[INFO] New best model saved at epoch 6 with val_loss=0.9188\n",
            "Training:  14% 1/7 [10:51<1:05:08, 651.34s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 8: Train: accuracy 0.7644, precision_macro 0.7632, recall_macro 0.7644, f1_macro 0.7636, loss 0.8621\n",
            "        Val: accuracy 0.7812, precision_macro 0.7834, recall_macro 0.7812, f1_macro 0.7785, loss 0.8877\n",
            "\n",
            "[INFO] New best model saved at epoch 7 with val_loss=0.8877\n",
            "Training:  29% 2/7 [21:01<52:15, 627.11s/it]  [INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 9: Train: accuracy 0.7818, precision_macro 0.7807, recall_macro 0.7818, f1_macro 0.7810, loss 0.7934\n",
            "        Val: accuracy 0.7720, precision_macro 0.7818, recall_macro 0.7720, f1_macro 0.7716, loss 0.9471\n",
            "\n",
            "[EarlyStopping] No improvement for 1 epoch(s)\n",
            "Training:  43% 3/7 [31:14<41:23, 620.75s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 10: Train: accuracy 0.8043, precision_macro 0.8037, recall_macro 0.8042, f1_macro 0.8037, loss 0.7045\n",
            "        Val: accuracy 0.7811, precision_macro 0.7872, recall_macro 0.7811, f1_macro 0.7798, loss 0.9365\n",
            "\n",
            "[EarlyStopping] No improvement for 2 epoch(s)\n",
            "Training:  57% 4/7 [41:32<30:58, 619.62s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 11: Train: accuracy 0.8241, precision_macro 0.8234, recall_macro 0.8241, f1_macro 0.8236, loss 0.6286\n",
            "        Val: accuracy 0.7877, precision_macro 0.7929, recall_macro 0.7877, f1_macro 0.7866, loss 0.9336\n",
            "\n",
            "[EarlyStopping] No improvement for 3 epoch(s)\n",
            "Training:  71% 5/7 [51:43<20:32, 616.49s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 12: Train: accuracy 0.8802, precision_macro 0.8800, recall_macro 0.8802, f1_macro 0.8800, loss 0.4319\n",
            "        Val: accuracy 0.8154, precision_macro 0.8167, recall_macro 0.8154, f1_macro 0.8143, loss 0.8165\n",
            "\n",
            "[INFO] New best model saved at epoch 11 with val_loss=0.8165\n",
            "Training:  86% 6/7 [1:01:57<10:15, 615.79s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 13: Train: accuracy 0.8788, precision_macro 0.8787, recall_macro 0.8787, f1_macro 0.8786, loss 0.4358\n",
            "        Val: accuracy 0.8196, precision_macro 0.8207, recall_macro 0.8196, f1_macro 0.8187, loss 0.8140\n",
            "\n",
            "[INFO] New best model saved at epoch 12 with val_loss=0.8140\n",
            "Training: 100% 7/7 [1:12:11<00:00, 618.81s/it]\n",
            "[INFO] Plot logged in MLflow run eceb4829e7114078a4613a547112585a\n",
            "[INFO] Plot URI: file:///content/drive/MyDrive/mlruns/186912651824771251/eceb4829e7114078a4613a547112585a/artifacts/plots/loss_curve.png\n"
          ]
        }
      ],
      "source": [
        "# Continue training\n",
        "!python -m scripts.retrain \\\n",
        "outputs.local.mlflow.path=/content/drive/MyDrive/mlruns \\\n",
        "outputs.local.mlflow.artifact_dir=/content/drive/MyDrive/artifacts \\\n",
        "retrain.run_path=/content/drive/MyDrive/mlruns/186912651824771251/5b50bf196aa441f794d71e132c2dff47 \\\n",
        "retrain.epochs_extra=7\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue training with proper lr if wanted\n",
        "!python -m scripts.retrain \\\n",
        "outputs.local.mlflow.path=/content/drive/MyDrive/mlruns \\\n",
        "outputs.local.mlflow.artifact_dir=/content/drive/MyDrive/artifacts \\\n",
        "retrain.run_path=/content/drive/MyDrive/mlruns/186912651824771251/eceb4829e7114078a4613a547112585a \\\n",
        "retrain.epochs_extra=3 \\\n",
        "train.optimizer.lr=0.0005  ## Should change manually to 0.001 in tracking for proper value"
      ],
      "metadata": {
        "id": "xc2EFwTPxF2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7b9451-0871-4826-abe4-1bba0eb0d74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "\r  0% 0.00/35.2M [00:00<?, ?B/s]\r 54% 19.1M/35.2M [00:00<00:00, 200MB/s]\r100% 35.2M/35.2M [00:00<00:00, 201MB/s]\n",
            "[INFO] Continuing training from run /content/drive/MyDrive/mlruns/186912651824771251/eceb4829e7114078a4613a547112585a\n",
            "[INFO] Loading previous training results from /content/drive/MyDrive/mlruns/186912651824771251/eceb4829e7114078a4613a547112585a/artifacts/metrics/training_results.json\n",
            "Training:   0% 0/3 [00:00<?, ?it/s][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 14: Train: accuracy 0.8610, precision_macro 0.8606, recall_macro 0.8610, f1_macro 0.8607, loss 0.4971\n",
            "        Val: accuracy 0.7761, precision_macro 0.7833, recall_macro 0.7761, f1_macro 0.7761, loss 0.9957\n",
            "\n",
            "Training:  33% 1/3 [11:17<22:35, 677.91s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 15: Train: accuracy 0.8682, precision_macro 0.8679, recall_macro 0.8682, f1_macro 0.8680, loss 0.4589\n",
            "        Val: accuracy 0.7849, precision_macro 0.7896, recall_macro 0.7849, f1_macro 0.7836, loss 1.0176\n",
            "\n",
            "[EarlyStopping] No improvement for 1 epoch(s)\n",
            "Training:  67% 2/3 [22:07<11:01, 661.33s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 16: Train: accuracy 0.8731, precision_macro 0.8728, recall_macro 0.8731, f1_macro 0.8729, loss 0.4380\n",
            "        Val: accuracy 0.7807, precision_macro 0.7863, recall_macro 0.7807, f1_macro 0.7799, loss 1.0410\n",
            "\n",
            "[EarlyStopping] No improvement for 2 epoch(s)\n",
            "Training: 100% 3/3 [32:54<00:00, 658.22s/it]\n",
            "[INFO] Plot logged in MLflow run 7b0dfd913a6f4a069f7b3b91f0668c15\n",
            "[INFO] Plot URI: file:///content/drive/MyDrive/mlruns/186912651824771251/7b0dfd913a6f4a069f7b3b91f0668c15/artifacts/plots/loss_curve.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7jiY3B8Kfau"
      },
      "source": [
        "## MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIlCN0o9K9A3",
        "outputId": "1f5e92a4-503a-4775-9c45-bf59f80368b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Starting training...\n",
            "Training:   0% 0/15 [00:00<?, ?it/s][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 1: Train: accuracy 0.3560, precision_macro 0.3409, recall_macro 0.3563, f1_macro 0.3446, loss 2.7929\n",
            "        Val: accuracy 0.5153, precision_macro 0.5325, recall_macro 0.5153, f1_macro 0.5034, loss 1.9564\n",
            "\n",
            "[INFO] New best model saved at epoch 0 with val_loss=1.9564\n",
            "Training:   7% 1/15 [06:32<1:31:32, 392.30s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 2: Train: accuracy 0.4508, precision_macro 0.4399, recall_macro 0.4510, f1_macro 0.4437, loss 2.2421\n",
            "        Val: accuracy 0.5439, precision_macro 0.5534, recall_macro 0.5439, f1_macro 0.5313, loss 1.8155\n",
            "\n",
            "[INFO] New best model saved at epoch 1 with val_loss=1.8155\n",
            "Training:  13% 2/15 [13:06<1:25:13, 393.38s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 3: Train: accuracy 0.4674, precision_macro 0.4586, recall_macro 0.4676, f1_macro 0.4614, loss 2.1328\n",
            "        Val: accuracy 0.6036, precision_macro 0.6211, recall_macro 0.6036, f1_macro 0.5978, loss 1.5540\n",
            "\n",
            "[INFO] New best model saved at epoch 2 with val_loss=1.5540\n",
            "Training:  20% 3/15 [20:06<1:21:05, 405.44s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 4: Train: accuracy 0.5487, precision_macro 0.5424, recall_macro 0.5489, f1_macro 0.5443, loss 1.7825\n",
            "        Val: accuracy 0.6418, precision_macro 0.6573, recall_macro 0.6418, f1_macro 0.6387, loss 1.4005\n",
            "\n",
            "[INFO] New best model saved at epoch 3 with val_loss=1.4005\n",
            "Training:  27% 4/15 [27:05<1:15:21, 411.03s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 5: Train: accuracy 0.5828, precision_macro 0.5783, recall_macro 0.5829, f1_macro 0.5797, loss 1.6154\n",
            "        Val: accuracy 0.6574, precision_macro 0.6700, recall_macro 0.6574, f1_macro 0.6536, loss 1.3319\n",
            "\n",
            "[INFO] New best model saved at epoch 4 with val_loss=1.3319\n",
            "Training:  33% 5/15 [34:07<1:09:08, 414.88s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 6: Train: accuracy 0.6124, precision_macro 0.6080, recall_macro 0.6126, f1_macro 0.6094, loss 1.4875\n",
            "        Val: accuracy 0.6814, precision_macro 0.6868, recall_macro 0.6814, f1_macro 0.6753, loss 1.2421\n",
            "\n",
            "[INFO] New best model saved at epoch 5 with val_loss=1.2421\n",
            "Training:  40% 6/15 [41:09<1:02:36, 417.36s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 7: Train: accuracy 0.6331, precision_macro 0.6298, recall_macro 0.6332, f1_macro 0.6307, loss 1.3975\n",
            "        Val: accuracy 0.6968, precision_macro 0.7103, recall_macro 0.6968, f1_macro 0.6970, loss 1.2201\n",
            "\n",
            "[INFO] New best model saved at epoch 6 with val_loss=1.2201\n",
            "Training:  47% 7/15 [48:09<55:45, 418.23s/it]  [INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 8: Train: accuracy 0.6529, precision_macro 0.6498, recall_macro 0.6530, f1_macro 0.6508, loss 1.3185\n",
            "        Val: accuracy 0.7093, precision_macro 0.7154, recall_macro 0.7093, f1_macro 0.7070, loss 1.1594\n",
            "\n",
            "[INFO] New best model saved at epoch 7 with val_loss=1.1594\n",
            "Training:  53% 8/15 [55:07<48:47, 418.22s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 9: Train: accuracy 0.6690, precision_macro 0.6658, recall_macro 0.6691, f1_macro 0.6669, loss 1.2491\n",
            "        Val: accuracy 0.7154, precision_macro 0.7215, recall_macro 0.7154, f1_macro 0.7134, loss 1.1356\n",
            "\n",
            "[INFO] New best model saved at epoch 8 with val_loss=1.1356\n",
            "Training:  60% 9/15 [1:02:04<41:46, 417.83s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 10: Train: accuracy 0.6841, precision_macro 0.6815, recall_macro 0.6842, f1_macro 0.6823, loss 1.1884\n",
            "        Val: accuracy 0.7119, precision_macro 0.7167, recall_macro 0.7119, f1_macro 0.7077, loss 1.1521\n",
            "\n",
            "[EarlyStopping] No improvement for 1 epoch(s)\n",
            "Training:  67% 10/15 [1:09:01<34:46, 417.33s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 11: Train: accuracy 0.6980, precision_macro 0.6959, recall_macro 0.6981, f1_macro 0.6965, loss 1.1267\n",
            "        Val: accuracy 0.7257, precision_macro 0.7313, recall_macro 0.7257, f1_macro 0.7238, loss 1.0700\n",
            "\n",
            "[INFO] New best model saved at epoch 10 with val_loss=1.0700\n",
            "Training:  73% 11/15 [1:16:00<27:51, 417.94s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 12: Train: accuracy 0.7094, precision_macro 0.7075, recall_macro 0.7095, f1_macro 0.7080, loss 1.0784\n",
            "        Val: accuracy 0.7207, precision_macro 0.7265, recall_macro 0.7207, f1_macro 0.7172, loss 1.1024\n",
            "\n",
            "[EarlyStopping] No improvement for 1 epoch(s)\n",
            "Training:  80% 12/15 [1:22:54<20:50, 416.69s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 13: Train: accuracy 0.7193, precision_macro 0.7178, recall_macro 0.7194, f1_macro 0.7182, loss 1.0387\n",
            "        Val: accuracy 0.7229, precision_macro 0.7256, recall_macro 0.7229, f1_macro 0.7202, loss 1.1002\n",
            "\n",
            "[EarlyStopping] No improvement for 2 epoch(s)\n",
            "Training:  87% 13/15 [1:29:49<13:52, 416.20s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 14: Train: accuracy 0.7316, precision_macro 0.7304, recall_macro 0.7316, f1_macro 0.7307, loss 0.9940\n",
            "        Val: accuracy 0.7291, precision_macro 0.7354, recall_macro 0.7291, f1_macro 0.7260, loss 1.0860\n",
            "\n",
            "[EarlyStopping] No improvement for 3 epoch(s)\n",
            "Training:  93% 14/15 [1:36:45<06:56, 416.09s/it][INFO] Starting train step...\n",
            "[INFO] Starting val step...\n",
            "Epoch 15: Train: accuracy 0.7927, precision_macro 0.7917, recall_macro 0.7928, f1_macro 0.7917, loss 0.7620\n",
            "        Val: accuracy 0.7613, precision_macro 0.7628, recall_macro 0.7613, f1_macro 0.7599, loss 0.9621\n",
            "\n",
            "[INFO] New best model saved at epoch 14 with val_loss=0.9621\n",
            "Training: 100% 15/15 [1:43:43<00:00, 414.89s/it]\n",
            "[INFO] Plot logged in MLflow run ad4c5ab130f74ac4ab598a64dd5170b9\n",
            "[INFO] Plot URI: file:///content/drive/MyDrive/mlruns/186912651824771251/ad4c5ab130f74ac4ab598a64dd5170b9/artifacts/plots/loss_curve.png\n"
          ]
        }
      ],
      "source": [
        "!python -m scripts.train model=mobilenet \\\n",
        " model.version=v2 model.pretrained=true\\\n",
        "  train.optimizer.lr=0.001 train.batch_size=16\\\n",
        "  train.epochs=15 train.augmentation=TrivialAugmentWide\\\n",
        "   train.unfreeze_layers=14 train.subset_percentage=0.7 \\\n",
        "    train.scheduler.type=ReduceLROnPlateau\\\n",
        "    outputs.local.mlflow.path=/content/drive/MyDrive/mlruns\\\n",
        "    outputs.local.mlflow.artifact_dir=/content/drive/MyDrive/artifacts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWyttSnspRqx"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select all 7\n",
        "\n",
        "!python -m scripts.select_models select_model.top_k=7 \\\n",
        "select_model.source_runs_dir=/content/drive/MyDrive/mlruns/186912651824771251 \\\n",
        "select_model.target_selected_models_dir=/content/drive/MyDrive/selected_models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scDoIPTAWJ1i",
        "outputId": "5b3c4996-fa9c-4940-d654-52f941ae56b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded 101 class names\n",
            "[INFO] Updated best_model_info.json at /content/drive/MyDrive/selected_models/efficientnet_b2_3b030/artifacts/best_model_info/best_model_info.json\n",
            "[INFO] Updated best_model_info.json at /content/drive/MyDrive/selected_models/efficientnet_b2_c9f35/artifacts/best_model_info/best_model_info.json\n",
            "[INFO] Updated best_model_info.json at /content/drive/MyDrive/selected_models/efficientnet_b0_c5274/artifacts/best_model_info/best_model_info.json\n",
            "[INFO] Updated best_model_info.json at /content/drive/MyDrive/selected_models/efficientnet_b0_e37ff/artifacts/best_model_info/best_model_info.json\n",
            "[INFO] Updated best_model_info.json at /content/drive/MyDrive/selected_models/efficientnet_b0_5e573/artifacts/best_model_info/best_model_info.json\n",
            "[INFO] Updated best_model_info.json at /content/drive/MyDrive/selected_models/mobilenet_v2_68ac8/artifacts/best_model_info/best_model_info.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuDM2TAGp05O",
        "outputId": "1c84d2a0-76a2-4182-f43a-e3393cf47e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Testing 6 models...\n",
            "[INFO] Collected transforms for model: efficientnet, version: b2\n",
            "[INFO] Collected transforms for model: efficientnet, version: b2\n",
            "[INFO] Collected transforms for model: efficientnet, version: b0\n",
            "[INFO] Collected transforms for model: efficientnet, version: b0\n",
            "[INFO] Collected transforms for model: efficientnet, version: b0\n",
            "[INFO] Collected transforms for model: mobilenet, version: v2\n",
            "[INFO] Using loss function: CrossEntropyLoss\n",
            "[INFO] Using metrics: ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
            "[INFO] Device: cuda\n",
            "Evaluating models:   0% 0/6 [00:00<?, ?model/s]\n",
            "[INFO] Evaluating run: efficientnet_b2_3b030 (Model: efficientnet, Version: b2)\n",
            "[INFO] Updated test results in /content/drive/MyDrive/selected_models/efficientnet_b2_3b030/artifacts/best_model_info/best_model_info.json\n",
            "[RESULTS] Metrics:\n",
            "  accuracy: 0.8153\n",
            "  precision_macro: 0.8160\n",
            "  recall_macro: 0.8153\n",
            "  f1_macro: 0.8145\n",
            "  loss: 0.8013\n",
            "  confusion_matrix: (array or list, not displayed)\n",
            "[INFO] JSON results: file:///content/drive/MyDrive/selected_models/efficientnet_b2_3b030/test/test.json\n",
            "[INFO] Confusion Matrix image not saved.\n",
            "Evaluating models:  17% 1/6 [02:56<14:44, 176.97s/model]\n",
            "[INFO] Evaluating run: efficientnet_b2_c9f35 (Model: efficientnet, Version: b2)\n",
            "[INFO] Updated test results in /content/drive/MyDrive/selected_models/efficientnet_b2_c9f35/artifacts/best_model_info/best_model_info.json\n",
            "[RESULTS] Metrics:\n",
            "  accuracy: 0.7600\n",
            "  precision_macro: 0.7679\n",
            "  recall_macro: 0.7600\n",
            "  f1_macro: 0.7587\n",
            "  loss: 0.9237\n",
            "  confusion_matrix: (array or list, not displayed)\n",
            "[INFO] JSON results: file:///content/drive/MyDrive/selected_models/efficientnet_b2_c9f35/test/test.json\n",
            "[INFO] Confusion Matrix image not saved.\n",
            "Evaluating models:  33% 2/6 [05:42<11:21, 170.29s/model]\n",
            "[INFO] Evaluating run: efficientnet_b0_c5274 (Model: efficientnet, Version: b0)\n",
            "[INFO] Updated test results in /content/drive/MyDrive/selected_models/efficientnet_b0_c5274/artifacts/best_model_info/best_model_info.json\n",
            "[RESULTS] Metrics:\n",
            "  accuracy: 0.7578\n",
            "  precision_macro: 0.7601\n",
            "  recall_macro: 0.7578\n",
            "  f1_macro: 0.7555\n",
            "  loss: 0.9839\n",
            "  confusion_matrix: (array or list, not displayed)\n",
            "[INFO] JSON results: file:///content/drive/MyDrive/selected_models/efficientnet_b0_c5274/test/test.json\n",
            "[INFO] Confusion Matrix image not saved.\n",
            "Evaluating models:  50% 3/6 [07:56<07:41, 153.90s/model]\n",
            "[INFO] Evaluating run: efficientnet_b0_e37ff (Model: efficientnet, Version: b0)\n",
            "[INFO] Updated test results in /content/drive/MyDrive/selected_models/efficientnet_b0_e37ff/artifacts/best_model_info/best_model_info.json\n",
            "[RESULTS] Metrics:\n",
            "  accuracy: 0.7643\n",
            "  precision_macro: 0.7653\n",
            "  recall_macro: 0.7643\n",
            "  f1_macro: 0.7621\n",
            "  loss: 0.9879\n",
            "  confusion_matrix: (array or list, not displayed)\n",
            "[INFO] JSON results: file:///content/drive/MyDrive/selected_models/efficientnet_b0_e37ff/test/test.json\n",
            "[INFO] Confusion Matrix image not saved.\n",
            "Evaluating models:  67% 4/6 [10:11<04:52, 146.16s/model]\n",
            "[INFO] Evaluating run: efficientnet_b0_5e573 (Model: efficientnet, Version: b0)\n",
            "[INFO] Updated test results in /content/drive/MyDrive/selected_models/efficientnet_b0_5e573/artifacts/best_model_info/best_model_info.json\n",
            "[RESULTS] Metrics:\n",
            "  accuracy: 0.7643\n",
            "  precision_macro: 0.7653\n",
            "  recall_macro: 0.7643\n",
            "  f1_macro: 0.7621\n",
            "  loss: 0.9879\n",
            "  confusion_matrix: (array or list, not displayed)\n",
            "[INFO] JSON results: file:///content/drive/MyDrive/selected_models/efficientnet_b0_5e573/test/test.json\n",
            "[INFO] Confusion Matrix image not saved.\n",
            "Evaluating models:  83% 5/6 [12:24<02:21, 141.55s/model]\n",
            "[INFO] Evaluating run: mobilenet_v2_68ac8 (Model: mobilenet, Version: v2)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
            "\n",
            "100% 13.6M/13.6M [00:00<00:00, 217MB/s]\n"
          ]
        }
      ],
      "source": [
        "!python -m scripts.test test.runs_dir=/content/drive/MyDrive/selected_models\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}